# üöÄ Simula√ß√£o de Entrevista T√©cnica: Engenharia de Dados (Microsoft)

Este reposit√≥rio documenta uma simula√ß√£o de entrevista t√©cnica conduzida por uma Intelig√™ncia Artificial (atuando como um Recrutador S√™nior da Microsoft). O objetivo foi avaliar compet√™ncias em **Engenharia de Dados**, **Big Data**, **Resolu√ß√£o de Problemas** e **Fit Cultural**.

**üìÖ Data:** 22/01/2026
**üéØ Vaga:** Engenheiro de Dados
**ü§ñ Entrevistador:** Alex (AI Persona - Senior Tech Recruiter)

---

## üõ†Ô∏è Stack e Tecnologias Abordadas
* **Processamento:** Apache Spark (PySpark), Otimiza√ß√£o (Catalyst, Broadcast).
* **Orquestra√ß√£o & Containeriza√ß√£o:** Airflow, Docker.
* **Armazenamento:** Data Lake, Parquet, Delta Lake, PostgreSQL.
* **Conceitos:** ETL, Modelagem de Dados, Tuning de Performance, Qualidade de Dados.

---

## üìù Transcri√ß√£o da Entrevista

### 1. Introdu√ß√£o e Background
**Recrutador:** Voc√™ poderia fazer uma breve apresenta√ß√£o sobre voc√™? Destaque os marcos que o levaram √† Engenharia de Dados.

> **Candidato:** Atualmente sou estagi√°rio na √°rea de Engenharia de Dados dentro do time de arquitetura de TI. Meu dia a dia envolve monitoramento de ferramentas e condu√ß√£o de projetos. Trabalho diariamente com Spark, Airbyte, Airflow, Docker, DBeaver, PostgreSQL, Python e Apache Hop. Minha motiva√ß√£o vem do gosto pela tecnologia, pela programa√ß√£o e pela identifica√ß√£o com a √°rea de dados.

### 2. Hard Skills: Transforma√ß√£o e Performance (Spark)
**Recrutador:** Pensando em um cen√°rio onde a performance √© um problema, como voc√™ lida com Joins entre uma tabela gigante (Terabytes) e uma pequena? Que estrat√©gia usaria no Spark?

> **Candidato:** Se uma das tabelas for pequena (geralmente abaixo de 100MB ou que caiba na mem√≥ria), a estrat√©gia imediata seria for√ßar um **Broadcast Join**. Isso copia a tabela menor para todos os n√≥s do cluster, permitindo que o Spark realize o cruzamento localmente sem precisar trafegar a tabela gigante pela rede, o que elimina o pesado processo de *Shuffle*.

### 3. Hard Skills: Armazenamento e Formatos
**Recrutador:** Por que, em um cen√°rio de Big Data, damos prefer√™ncia a formatos colunares (Parquet/Delta) em vez de CSV ou JSON?

> **Candidato:** Como engenheiro de dados, a regra √© clara: em um Data Lake produtivo, formatos de texto como CSV e JSON servem apenas para a zona de Landing ou trocas de arquivos pequenos. Para as camadas de processamento (Silver/Gold) e consumo, formatos colunares como **Parquet** ou **Delta** s√£o obrigat√≥rios por quest√µes de efici√™ncia f√≠sica (compress√£o e leitura seletiva de colunas).

### 4. Resolu√ß√£o de Problemas (Case: Silent Failure)
**Recrutador:** Um pipeline no Airflow ficou "verde" (sucesso), mas o Diretor Financeiro relata dados duplicados. O que voc√™ faria para investigar a causa raiz?

> **Candidato:** Essa √© uma situa√ß√£o de "Silent Failure". Primeiro, preciso confirmar se a duplicidade √© uma c√≥pia exata (reprocessamento indevido) ou uma explos√£o de dados (join errado). Executaria uma query r√°pida na tabela de destino agrupando pela chave prim√°ria (ID) e pela data de ingest√£o para diagnosticar a origem do problema.

### 5. Comportamental e Comunica√ß√£o T√©cnica
**Recrutador:** Conte sobre uma situa√ß√£o onde voc√™ teve uma discord√¢ncia t√©cnica com um colega. Qual foi o argumento t√©cnico usado?

> **Candidato:** Tivemos uma discuss√£o sobre o uso de fun√ß√µes nativas do Spark versus UDFs em Python puro. Argumentei que o Spark roda na JVM e, ao usar fun√ß√µes nativas, aproveitamos o **Catalyst Optimizer**. O uso de Python puro exige serializa√ß√£o/deserializa√ß√£o de dados entre a JVM e o Python, gerando um custo alto de performance. Apresentando esses fatos, o time optou pela abordagem nativa.

### 6. Fit Cultural e Aprendizado (Growth Mindset)
**Recrutador:** Como voc√™ se mant√©m atualizado na √°rea?

> **Candidato:** Al√©m da documenta√ß√£o oficial, participo de comunidades de Engenharia de Dados e leio blogs de engenharia de grandes empresas (*Big Techs*) como Netflix e Uber para entender como eles resolvem problemas de arquitetura e escala.

---

## üìä Feedback do Recrutador (Simulado)

O candidato demonstrou um n√≠vel de senioridade t√©cnica acima da m√©dia para a posi√ß√£o atual (estagi√°rio), com destaque para:

1.  **Profundidade em Spark:** Entendimento claro de *internals* (Shuffle, Broadcast, JVM vs Python serialization).
2.  **Investiga√ß√£o de Problemas:** Abordagem l√≥gica para diferenciar erros de infraestrutura de erros l√≥gicos (*Silent Failures*).
3.  **Boas Pr√°ticas:** Vis√£o correta sobre camadas de Data Lake e escolha de formatos de arquivo.

**Resultado:** Recomendado para a pr√≥xima fase (Live Coding).

---
*Gerado via simula√ß√£o de entrevista com IA.*
